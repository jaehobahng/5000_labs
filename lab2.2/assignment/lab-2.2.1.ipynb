{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Lab-2.2: Cleaning record data in R and Python\n","\n","*Author James Hickman, post any questions to slack* \n","\n","**Instructions** \n","\n","* Part-1: Read and work through all tutorial content and do all exercises below using python\n","* Part-2: Create a .rmd file, copy all markdown content into the .rmd file, and repeat all coding exercises below in R instead of python (using tibbles instead of data-frames)\n","\n","**Submission:**\n","\n","* You need to upload TWO documents to Canvas when you are done\n","  * (1) A PDF (or HTML) of the completed .ipynb document (python submission) \n","  * (2) A PDF (or HTML) of the completed .qmd document (R submission) \n","* **BOTH ARE REQUIRED, YOU CANNOT DO JUST ONE OR THE OTHER**\n","* The final uploaded version should NOT have any code-errors present \n","* All outputs must be visible in the uploaded version, including code-cell outputs, images, graphs, etc"]},{"cell_type":"markdown","metadata":{},"source":["### Cleaning record data \n","\n","In practice, there is no \"one size fits all\" method for data cleaning. \n","\n","How you clean the data depends on your objective and what kind of data you have (e.g. record, text, transaction,.. etc) \n","\n","Record data is very common, therefore we will focus on this as a example case, specifically the following common operations. \n","\n","* merging data frames\n","* Removing un-needed columns \n","* Dealing with missing values and non-sense values \n","* standardization \n","* normalization \n","\n","We will intentionally focus on an overly simply toy data set, the focus is on the operations, not the complexity of the data"]},{"cell_type":"code","execution_count":263,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["### Read in the data \n","\n","* Use pandas to read in the \"example-1.csv\" and \"example-2.csv\" files in the folder named \"data\"\n","  \n","* Before moving further, open the files in VSC, install relevant .csv extensions (optional), manually expect the data and look for obvious issues \n"]},{"cell_type":"code","execution_count":264,"metadata":{},"outputs":[],"source":["# INSERT CODE TO READ THE DATA FILES (hint .. google --> \"how to read csv file with pandas\")\n","df1 = pd.read_csv(\"./data/example-1.csv\")\n","df2= pd.read_csv(\"./data/example-2.csv\")"]},{"cell_type":"code","execution_count":265,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  initials   age  account_balance_usd  yearly_income_usd\n","0            1       546    32                1232.            140230.\n","1            1     \"JKJ\"    32                1232.              \"USA\"\n","2            2     \"LKS\"    13               23023.             2100.0\n","3            3     \"UKS\"   -23               13023.            56000.0\n","4            4     \"ESA\"                     15023.           265000.0\n","5            5     \"ILK\"    24                                261000.0\n","6            6     \"JKL\"    53                143.            261000.0\n","7            7     \"JKL\"    53                143.            261000.0\n"]}],"source":["print(df1)"]},{"cell_type":"code","execution_count":266,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id   num_children   is_house_owner   housing_payment_pesos country\n","0            1              3              0.0                 22000.0   \"usa\"\n","1            2              0              NaN                 22450.0    \"US\"\n","2            3              1              1.0                 35000.0   \"USA\"\n","3            4           1232              1.0                 23040.0   \"MEX\"\n","4            6              3              0.0                 24340.0   \"mex\"\n","5            7              3              0.0                 24140.0   \"MEX\"\n"]}],"source":["print(df2)"]},{"cell_type":"code","execution_count":267,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id   num_children   is_house_owner   housing_payment_pesos country\n","0            1              3              0.0                 22000.0   \"usa\"\n","1            2              0              NaN                 22450.0    \"US\"\n"]}],"source":["# LOOK AT FIRST COUPLE LINES\n","print(df2.head(2))"]},{"cell_type":"code","execution_count":268,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id   num_children   is_house_owner   housing_payment_pesos country\n","4            6              3              0.0                 24340.0   \"mex\"\n","5            7              3              0.0                 24140.0   \"MEX\"\n"]}],"source":["# LOOK AT LAST COUPLE LINES\n","print(df2.tail(2))"]},{"cell_type":"markdown","metadata":{},"source":["Notice that some column names have spaces, lets get rid of those"]},{"cell_type":"code","execution_count":269,"metadata":{},"outputs":[],"source":["## INSERT CODE TO REMOVE SPACES FROM COLUMN NAMES\n","df1.columns = [col.replace(' ','') for col in df1.columns]\n","df2.columns = [col.replace(' ','') for col in df2.columns]"]},{"cell_type":"markdown","metadata":{},"source":["Lets also clean up some of the column names"]},{"cell_type":"code","execution_count":270,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['customer_id', 'initials', 'age_years', 'account_balance_usd',\n","       'yearly_income_usd'],\n","      dtype='object') Index(['customer_id', 'num_children', 'is_house_owner',\n","       'housing_payment_pesos', 'country_of_origin'],\n","      dtype='object')\n"]}],"source":["# INSERT CODE TO RENAME THE COLUMN NAME \"age\" --> \"age_years\" and \"country\" as \"country_of_origin\"\n","# PRINT THE MODIFIED COLUMN NAMES WHEN DONE\n","df1.rename(columns={\"age\" : \"age_years\"}, inplace = True)\n","df2.rename(columns={\"country\" : \"country_of_origin\"}, inplace = True)\n","\n","print(df1.columns,df2.columns)"]},{"cell_type":"markdown","metadata":{},"source":["### Standardizing values \n","\n","Standardization typically means forcing everything to use the same \"standard\" units \n","\n","For example, making sure all weights are in lb, all money values are in USD, etc. \n","\n","You can typically use any units, it doesn't really matter which you choose as long as everything is the same.\n","\n","It is good to do this before merging your data, because it would be very bad to have a column of data with mixed units. \n","\n","A column with mixed units is basically non-sense. \n","\n","For example, what is the meaning of averaging a vector of house prices where half of the values are USD and the other half is Pesos.\n"]},{"cell_type":"code","execution_count":271,"metadata":{},"outputs":[{"data":{"text/plain":["customer_id                int64\n","num_children               int64\n","is_house_owner           float64\n","housing_payment_pesos    float64\n","country_of_origin         object\n","dtype: object"]},"execution_count":271,"metadata":{},"output_type":"execute_result"}],"source":["#INSERT CODE TO CONVERT TYPECAST \"housing_payment_pesos\" AS TYPE \"FLOAT\"\n","df2['housing_payment_pesos'] = df2.housing_payment_pesos.astype('float')\n","df2.dtypes"]},{"cell_type":"code","execution_count":272,"metadata":{},"outputs":[],"source":["#INSERT CODE TO CONVERT \"housing_payment_pesos\" to USD\n","# 1 Mexican Peso = 0.050 USD\n","# 1 USD = 19.88 Mexican Peso\n","df2[\"housing_payment_pesos\"] = df2[\"housing_payment_pesos\"]/19.88"]},{"cell_type":"code","execution_count":273,"metadata":{},"outputs":[],"source":["#INSERT CODE TO RENAME \"housing_payment_pesos\" to \"housing_payment_usd\"\n","df2.rename(columns={\"housing_payment_pesos\" : \"housing_payment_usd\"}, inplace = True)"]},{"cell_type":"code","execution_count":274,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  num_children  is_house_owner  housing_payment_usd  \\\n","0            1             3             0.0          1106.639839   \n","1            2             0             NaN          1129.275654   \n","2            3             1             1.0          1760.563380   \n","3            4          1232             1.0          1158.953722   \n","4            6             3             0.0          1224.346076   \n","5            7             3             0.0          1214.285714   \n","\n","  country_of_origin  \n","0             \"usa\"  \n","1              \"US\"  \n","2             \"USA\"  \n","3             \"MEX\"  \n","4             \"mex\"  \n","5             \"MEX\"  \n"]}],"source":["# PRINT THE MODIFIED DATA FRAME\n","print(df2)"]},{"cell_type":"markdown","metadata":{},"source":["another part of the standardization process is making sure all labels are consistently defined  \n","\n","Notice how \"usa\", \"US\", etc"]},{"cell_type":"code","execution_count":275,"metadata":{},"outputs":[],"source":["## RUN THE FOLLOWING CELL TO REMOVE ANY WHITE SPACE FROM \"country_of_origin\"\n","df2['country_of_origin']=df2['country_of_origin'].str.strip()"]},{"cell_type":"code","execution_count":276,"metadata":{},"outputs":[{"data":{"text/plain":["array(['\"usa\"', '\"US\"', '\"USA\"', '\"MEX\"', '\"mex\"'], dtype=object)"]},"execution_count":276,"metadata":{},"output_type":"execute_result"}],"source":["# INSERT CODE TO MAKE SURE ALL \"US\" TAGS equal \"usa\" and all \"MEX\" tags equal \"mex\"\n","df2[\"country_of_origin\"].unique()"]},{"cell_type":"code","execution_count":277,"metadata":{},"outputs":[{"data":{"text/plain":["array(['\"usa\"', '\"mex\"'], dtype=object)"]},"execution_count":277,"metadata":{},"output_type":"execute_result"}],"source":["format_mapping = {\n","    '\"us\"' : '\"usa\"'\n","}\n","\n","df2['country_of_origin'] = df2['country_of_origin'].str.lower().replace(format_mapping)\n","\n","df2['country_of_origin'].unique()"]},{"cell_type":"code","execution_count":278,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  num_children  is_house_owner  housing_payment_usd  \\\n","0            1             3             0.0          1106.639839   \n","1            2             0             NaN          1129.275654   \n","2            3             1             1.0          1760.563380   \n","3            4          1232             1.0          1158.953722   \n","4            6             3             0.0          1224.346076   \n","5            7             3             0.0          1214.285714   \n","\n","  country_of_origin  \n","0             \"usa\"  \n","1             \"usa\"  \n","2             \"usa\"  \n","3             \"mex\"  \n","4             \"mex\"  \n","5             \"mex\"  \n"]}],"source":["# PRINT THE DATA FRAME\n","print(df2)"]},{"cell_type":"markdown","metadata":{},"source":["### Merging data sets \n","\n","The easiest way to merge data files is when a \"common-key\" exists (i.e. a column shared by both files) \n","\n","In our toy example the customer_id can be used as a common key \n","\n","Data sets are typically merged using SQL type join operations (inner,outer,left,right). \n","\n","See the lecture slides for examples and codes for these join operations. "]},{"cell_type":"code","execution_count":279,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>initials</th>\n","      <th>age_years</th>\n","      <th>account_balance_usd</th>\n","      <th>yearly_income_usd</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>546</td>\n","      <td>32</td>\n","      <td>1232.</td>\n","      <td>140230.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>\"JKJ\"</td>\n","      <td>32</td>\n","      <td>1232.</td>\n","      <td>\"USA\"</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>\"LKS\"</td>\n","      <td>13</td>\n","      <td>23023.</td>\n","      <td>2100.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>\"UKS\"</td>\n","      <td>-23</td>\n","      <td>13023.</td>\n","      <td>56000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>\"ESA\"</td>\n","      <td></td>\n","      <td>15023.</td>\n","      <td>265000.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>\"ILK\"</td>\n","      <td>24</td>\n","      <td></td>\n","      <td>261000.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>\"JKL\"</td>\n","      <td>53</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>\"JKL\"</td>\n","      <td>53</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id initials age_years account_balance_usd yearly_income_usd\n","0            1      546        32               1232.           140230.\n","1            1    \"JKJ\"        32               1232.             \"USA\"\n","2            2    \"LKS\"        13              23023.            2100.0\n","3            3    \"UKS\"       -23              13023.           56000.0\n","4            4    \"ESA\"                        15023.          265000.0\n","5            5    \"ILK\"        24                              261000.0\n","6            6    \"JKL\"        53               143.           261000.0\n","7            7    \"JKL\"        53               143.           261000.0"]},"execution_count":279,"metadata":{},"output_type":"execute_result"}],"source":["df1"]},{"cell_type":"code","execution_count":280,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":280,"metadata":{},"output_type":"execute_result"}],"source":["df2['customer_id'].nunique() == len(df2)"]},{"cell_type":"code","execution_count":281,"metadata":{},"outputs":[],"source":["# INSERT CODE TO DO AN \"OUTER\" JOIN FOR THE TWO DATA-FRAMES USING \"CUSTOMER_ID\" AS COMMON KEY\n","# (hint .. see lecture slides)\n","df = df1.merge(df2,on='customer_id',how='outer')"]},{"cell_type":"code","execution_count":282,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id initials age_years account_balance_usd yearly_income_usd  \\\n","0            1      546        32               1232.           140230.   \n","1            1    \"JKJ\"        32               1232.             \"USA\"   \n","2            2    \"LKS\"        13              23023.            2100.0   \n","3            3    \"UKS\"       -23              13023.           56000.0   \n","4            4    \"ESA\"                        15023.          265000.0   \n","5            5    \"ILK\"        24                              261000.0   \n","6            6    \"JKL\"        53               143.           261000.0   \n","7            7    \"JKL\"        53               143.           261000.0   \n","\n","   num_children  is_house_owner  housing_payment_usd country_of_origin  \n","0           3.0             0.0          1106.639839             \"usa\"  \n","1           3.0             0.0          1106.639839             \"usa\"  \n","2           0.0             NaN          1129.275654             \"usa\"  \n","3           1.0             1.0          1760.563380             \"usa\"  \n","4        1232.0             1.0          1158.953722             \"mex\"  \n","5           NaN             NaN                  NaN               NaN  \n","6           3.0             0.0          1224.346076             \"mex\"  \n","7           3.0             0.0          1214.285714             \"mex\"  \n"]}],"source":["print(df)"]},{"cell_type":"markdown","metadata":{},"source":["Notice how the merge injected \"NaN\" where merge wasn't possible\n","\n","Notice that we also have missing values (empty cells), let's replace those with NaN. \n","\n","That way all missing values will be represented the same way"]},{"cell_type":"code","execution_count":283,"metadata":{},"outputs":[],"source":["# INSERT CODE TO: REPLACE ALL CELLS THAT ARE ENTIRELY SPACE (OR EMPTY) WITH NAN \n","# (use google to figure out how to do this)\n","df.replace(' ',np.nan,inplace=True)\n","df.replace('',np.nan,inplace=True)"]},{"cell_type":"code","execution_count":284,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id initials age_years account_balance_usd yearly_income_usd  \\\n","0            1      546        32               1232.           140230.   \n","1            1    \"JKJ\"        32               1232.             \"USA\"   \n","2            2    \"LKS\"        13              23023.            2100.0   \n","3            3    \"UKS\"       -23              13023.           56000.0   \n","4            4    \"ESA\"       NaN              15023.          265000.0   \n","5            5    \"ILK\"        24                 NaN          261000.0   \n","6            6    \"JKL\"        53               143.           261000.0   \n","7            7    \"JKL\"        53               143.           261000.0   \n","\n","   num_children  is_house_owner  housing_payment_usd country_of_origin  \n","0           3.0             0.0          1106.639839             \"usa\"  \n","1           3.0             0.0          1106.639839             \"usa\"  \n","2           0.0             NaN          1129.275654             \"usa\"  \n","3           1.0             1.0          1760.563380             \"usa\"  \n","4        1232.0             1.0          1158.953722             \"mex\"  \n","5           NaN             NaN                  NaN               NaN  \n","6           3.0             0.0          1224.346076             \"mex\"  \n","7           3.0             0.0          1214.285714             \"mex\"  \n"]}],"source":["print(df)"]},{"cell_type":"code","execution_count":285,"metadata":{},"outputs":[{"data":{"text/plain":["(8, 9)"]},"execution_count":285,"metadata":{},"output_type":"execute_result"}],"source":["# INSERT CODE TO PRINT THE SHAPE OF THE NEW DATAFRAME\n","df.shape"]},{"cell_type":"markdown","metadata":{},"source":["Lets see how many missing values there are in each column"]},{"cell_type":"code","execution_count":286,"metadata":{},"outputs":[{"data":{"text/plain":["customer_id            0\n","initials               0\n","age_years              1\n","account_balance_usd    1\n","yearly_income_usd      0\n","num_children           1\n","is_house_owner         2\n","housing_payment_usd    1\n","country_of_origin      1\n","dtype: int64"]},"execution_count":286,"metadata":{},"output_type":"execute_result"}],"source":["# INSERT CODE TO COUNT THE NUMBER OF MISSING VALUES IN EACH COLUMN (use google)\n","df.isna().sum()"]},{"cell_type":"code","execution_count":287,"metadata":{},"outputs":[{"data":{"text/plain":["age_years              1\n","account_balance_usd    1\n","num_children           1\n","is_house_owner         2\n","housing_payment_usd    1\n","country_of_origin      1\n","dtype: int64"]},"execution_count":287,"metadata":{},"output_type":"execute_result"}],"source":["# INSERT CODE TO PRINT THE COLUMN NAMES\n","series = df.isna().sum()\n","series[series > 0]"]},{"cell_type":"markdown","metadata":{},"source":["### Throw away un-needed columns\n","\n","You don't want to remove an otherwise \"good\" row, just because a value is missing in a column that you don't care about.\n","\n","Therefore, typically it is good to get rid of un-needed columns before removing missing values. \n","\n","Lets assume that the variables \"initials\" and \"num_children\" won't be needed for future analysis and can be thrown away"]},{"cell_type":"code","execution_count":288,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id initials age_years account_balance_usd yearly_income_usd  \\\n","0            1      546        32               1232.           140230.   \n","1            1    \"JKJ\"        32               1232.             \"USA\"   \n","2            2    \"LKS\"        13              23023.            2100.0   \n","3            3    \"UKS\"       -23              13023.           56000.0   \n","4            4    \"ESA\"       NaN              15023.          265000.0   \n","5            5    \"ILK\"        24                 NaN          261000.0   \n","6            6    \"JKL\"        53               143.           261000.0   \n","7            7    \"JKL\"        53               143.           261000.0   \n","\n","   num_children  is_house_owner  housing_payment_usd country_of_origin  \n","0           3.0             0.0          1106.639839             \"usa\"  \n","1           3.0             0.0          1106.639839             \"usa\"  \n","2           0.0             NaN          1129.275654             \"usa\"  \n","3           1.0             1.0          1760.563380             \"usa\"  \n","4        1232.0             1.0          1158.953722             \"mex\"  \n","5           NaN             NaN                  NaN               NaN  \n","6           3.0             0.0          1224.346076             \"mex\"  \n","7           3.0             0.0          1214.285714             \"mex\"  \n"]}],"source":["print(df)"]},{"cell_type":"code","execution_count":289,"metadata":{},"outputs":[],"source":["### INSERT CODE TO REMOVE THE COLUMNS \"initials\" AND \"num_children\", \n","df.drop(columns = ['initials','num_children'],inplace=True)"]},{"cell_type":"code","execution_count":290,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(8, 7)\n","   customer_id age_years account_balance_usd yearly_income_usd  \\\n","0            1        32               1232.           140230.   \n","1            1        32               1232.             \"USA\"   \n","2            2        13              23023.            2100.0   \n","3            3       -23              13023.           56000.0   \n","4            4       NaN              15023.          265000.0   \n","5            5        24                 NaN          261000.0   \n","6            6        53               143.           261000.0   \n","7            7        53               143.           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839             \"usa\"  \n","1             0.0          1106.639839             \"usa\"  \n","2             NaN          1129.275654             \"usa\"  \n","3             1.0          1760.563380             \"usa\"  \n","4             1.0          1158.953722             \"mex\"  \n","5             NaN                  NaN               NaN  \n","6             0.0          1224.346076             \"mex\"  \n","7             0.0          1214.285714             \"mex\"  \n"]}],"source":["# INSERT CODE TO PRINT THE NEW DATA-FRAME AND ITS SHAPE\n","print(df.shape)\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["Before dealing with the missing values, notice that one row has \"nan\", which is a string, instead of the numpy NaN object.\n","\n","Lets fix that. "]},{"cell_type":"code","execution_count":291,"metadata":{},"outputs":[],"source":["## INSERT CODE TO REPLACE THE STRING \"nan\" WITH NAN, PRINT THE NEW DATA-FRAME WHEN DONE\n","df.replace('nan', np.nan, inplace=True)\n","df.replace('\"','',inplace=True,regex=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Dealing with non-sense values \n","\n","Often there are values in the data that are clearly NOT legitimate, such as negative ages, or strings where numbers should be.\n","\n","You want to remove these before doing any averaging or other statistics because they will tamper with the results. \n","\n","For example, the average is highly sensitive to outliers, so negative ages would badly skew the mean."]},{"cell_type":"code","execution_count":292,"metadata":{},"outputs":[],"source":["## RUN THE FOLLOWING CODE, THIS USES A CONDITIONAL TO ONLY KEEP ROWS WHERE \"age_years\"=NaN \n","df = df[df['age_years'].notna()]"]},{"cell_type":"code","execution_count":293,"metadata":{},"outputs":[],"source":["## INSERT CODE TO REPLACE ANY NEGATIVE \"age_years\" WITH NUMPY \"NaN\" OBJECT\n","## There are multiple ways to do this, for example you can iterate over the \n","# rows and use apply with a lambda function to enforce the conditional\n","df['age_years'] = df['age_years'].astype(int)\n","df['age_years'] = df['age_years'].apply(lambda x: np.nan if x < 0 else x)"]},{"cell_type":"code","execution_count":294,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>age_years</th>\n","      <th>account_balance_usd</th>\n","      <th>yearly_income_usd</th>\n","      <th>is_house_owner</th>\n","      <th>housing_payment_usd</th>\n","      <th>country_of_origin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>32.0</td>\n","      <td>1232.</td>\n","      <td>140230.</td>\n","      <td>0.0</td>\n","      <td>1106.639839</td>\n","      <td>usa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>32.0</td>\n","      <td>1232.</td>\n","      <td>USA</td>\n","      <td>0.0</td>\n","      <td>1106.639839</td>\n","      <td>usa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>13.0</td>\n","      <td>23023.</td>\n","      <td>2100.0</td>\n","      <td>NaN</td>\n","      <td>1129.275654</td>\n","      <td>usa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>13023.</td>\n","      <td>56000.0</td>\n","      <td>1.0</td>\n","      <td>1760.563380</td>\n","      <td>usa</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>24.0</td>\n","      <td>NaN</td>\n","      <td>261000.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>53.0</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","      <td>0.0</td>\n","      <td>1224.346076</td>\n","      <td>mex</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>53.0</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","      <td>0.0</td>\n","      <td>1214.285714</td>\n","      <td>mex</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id  age_years account_balance_usd yearly_income_usd  \\\n","0            1       32.0               1232.           140230.   \n","1            1       32.0               1232.               USA   \n","2            2       13.0              23023.            2100.0   \n","3            3        NaN              13023.           56000.0   \n","5            5       24.0                 NaN          261000.0   \n","6            6       53.0               143.           261000.0   \n","7            7       53.0               143.           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","1             0.0          1106.639839               usa  \n","2             NaN          1129.275654               usa  \n","3             1.0          1760.563380               usa  \n","5             NaN                  NaN               NaN  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  "]},"execution_count":294,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":295,"metadata":{},"outputs":[],"source":["## RUN THE FOLLOWING CELL TO REMOVE ANY WHITE SPACE FROM \"yearly_income_usd\"\n","df['yearly_income_usd']=df['yearly_income_usd'].str.strip()"]},{"cell_type":"code","execution_count":296,"metadata":{},"outputs":[],"source":["## INSERT CODE TO REPLACE ANY \"yearly_income_usd\" THAT IS A STRING WITH NUMPY nan OBJECT\n","df.loc[df['yearly_income_usd'].str.isalpha(),'yearly_income_usd'] = np.nan"]},{"cell_type":"code","execution_count":297,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  age_years account_balance_usd yearly_income_usd  \\\n","0            1       32.0               1232.           140230.   \n","1            1       32.0               1232.               NaN   \n","2            2       13.0              23023.            2100.0   \n","3            3        NaN              13023.           56000.0   \n","5            5       24.0                 NaN          261000.0   \n","6            6       53.0               143.           261000.0   \n","7            7       53.0               143.           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","1             0.0          1106.639839               usa  \n","2             NaN          1129.275654               usa  \n","3             1.0          1760.563380               usa  \n","5             NaN                  NaN               NaN  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  \n"]}],"source":["# PRINT THE DATA FRAME\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["### Dealing with missing values "]},{"cell_type":"markdown","metadata":{},"source":["There are many options to deal with missing values, some are better than others\n","\n","The easiest, and probably the worst option, is to just throw out any row with NaN"]},{"cell_type":"code","execution_count":298,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>age_years</th>\n","      <th>account_balance_usd</th>\n","      <th>yearly_income_usd</th>\n","      <th>is_house_owner</th>\n","      <th>housing_payment_usd</th>\n","      <th>country_of_origin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>32.0</td>\n","      <td>1232.</td>\n","      <td>140230.</td>\n","      <td>0.0</td>\n","      <td>1106.639839</td>\n","      <td>usa</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>53.0</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","      <td>0.0</td>\n","      <td>1224.346076</td>\n","      <td>mex</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>53.0</td>\n","      <td>143.</td>\n","      <td>261000.0</td>\n","      <td>0.0</td>\n","      <td>1214.285714</td>\n","      <td>mex</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id  age_years account_balance_usd yearly_income_usd  \\\n","0            1       32.0               1232.           140230.   \n","6            6       53.0               143.           261000.0   \n","7            7       53.0               143.           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  "]},"execution_count":298,"metadata":{},"output_type":"execute_result"}],"source":["# INSERT CODE TO THROW AWAY ANY ROW WITH \"NaN\" \n","# JUST PRINT THE OUTPUT, DONT RE-DEFINE THE DATAFRAME\n","# hint: read the documentation https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n","df.dropna()"]},{"cell_type":"markdown","metadata":{},"source":["**IMPORTANT README**\n","\n","Another option would be to replace the missing value with a typical value that summarizes that column, such as the mean, median, or mode. \n","\n","In practice, you need to be careful when doing this! You are essentially tampering with the data. \n","\n","You MUST document changes of this kind and be TRANSPARENT, otherwise it could be viewed as academic or professional dishonesty. \n","\n","Especially if it dramatically effects your results.\n","\n","Doing so will also effect all future analysis, since you are forcing a data point to become an \"average\" data point. \n","\n","For example, if you were looking for good basketball player's in a data driven way. Then replacing an unknown height with the \"mean\" would likely be a bad idea. \n","\n","In this case, you are making someone who might be 7 ft tall appear to be average height. \n","\n","You could also use more sophisticated methods such as MICE or regression to fill in the missing values (more on this next week).\n","\n","Finally, you might be able to logically infer the value from other columns in the data set.\n","\n","For example, if you have data on the price of someones house, you could likely predict their monthly payment assuming a typical 10-20% down payment and using a mortgage payment calculation formula.\n","\n","This would be acceptable as long as you document your assumptions, approximations, and methods. \n"]},{"cell_type":"code","execution_count":299,"metadata":{},"outputs":[{"data":{"text/plain":["customer_id            float64\n","age_years              float64\n","account_balance_usd    float64\n","yearly_income_usd      float64\n","is_house_owner         float64\n","housing_payment_usd    float64\n","country_of_origin       object\n","dtype: object"]},"execution_count":299,"metadata":{},"output_type":"execute_result"}],"source":["# SOMETIME PANDAS READS COLUMNS IN AS STRINGS RATHER THAN NUMBERS\n","# INSERT CODE TO TYPE-CAST ALL OF THE FOLLOWING COLUMNS AS FLOATS\n","# [\"customer_id\",\"age_years\",\"account_balance_usd\",\"yearly_income_usd\",\"housing_payment_usd\"]\n","columns_to_convert = [\"customer_id\",\"age_years\",\"account_balance_usd\",\"yearly_income_usd\",\"housing_payment_usd\"]\n","df[columns_to_convert] = df[columns_to_convert].astype(float)\n","df.dtypes"]},{"cell_type":"code","execution_count":300,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["age_years                  34.500000\n","account_balance_usd      6466.000000\n","yearly_income_usd      163555.000000\n","housing_payment_usd      1256.958417\n","dtype: float64\n"]}],"source":["# INSERT CODE TO COMPUTE AND PRINT THE MEAN,MEDIAN, AND STD DOWN THE COLUMNS (DO EACH IN ITS OWN CELL)\n","# NOTICE THAT ONLY THE NUMERICAL ROWS ARE COMPUTED (YOU CAN IGNORE ANY DEPRECATION WARNINGS)\n","# print((df[[\"age_years\",\"account_balance_usd\"]]).mean(axis=1))\n","\n","#MEAN\n","print((df[[\"age_years\",\"account_balance_usd\",\"yearly_income_usd\",\"housing_payment_usd\"]]).mean(axis=0))"]},{"cell_type":"code","execution_count":301,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["age_years                  32.000000\n","account_balance_usd      1232.000000\n","yearly_income_usd      200615.000000\n","housing_payment_usd      1171.780684\n","dtype: float64\n"]}],"source":["#MEDIAN \n","print((df[[\"age_years\",\"account_balance_usd\",\"yearly_income_usd\",\"housing_payment_usd\"]]).median(axis=0))"]},{"cell_type":"code","execution_count":302,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["age_years                  15.934240\n","account_balance_usd      9506.615255\n","yearly_income_usd      115469.852992\n","housing_payment_usd       252.189104\n","dtype: float64\n"]}],"source":["#STD\n","print((df[[\"age_years\",\"account_balance_usd\",\"yearly_income_usd\",\"housing_payment_usd\"]]).std(axis=0))"]},{"cell_type":"markdown","metadata":{},"source":["Lets now replace some of the \"NaN\" data with typical missing values "]},{"cell_type":"code","execution_count":303,"metadata":{},"outputs":[],"source":["# INSERT CODE TO REPLACE ANY \"NaN\" in \"age_years\" WITH THE AVERAGE\n","df[\"age_years\"] = df[\"age_years\"].replace(np.nan,df[\"age_years\"].mean())\n"]},{"cell_type":"code","execution_count":304,"metadata":{},"outputs":[],"source":["# INSERT CODE TO REPLACE ANY \"NaN\" in \"yearly_income_usd\" WITH THE MEDIAN\n","df[\"yearly_income_usd\"] = df[\"yearly_income_usd\"].replace(np.nan,df[\"yearly_income_usd\"].median())"]},{"cell_type":"code","execution_count":305,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  age_years  account_balance_usd  yearly_income_usd  \\\n","0          1.0       32.0               1232.0           140230.0   \n","1          1.0       32.0               1232.0           200615.0   \n","2          2.0       13.0              23023.0             2100.0   \n","3          3.0       34.5              13023.0            56000.0   \n","5          5.0       24.0                  NaN           261000.0   \n","6          6.0       53.0                143.0           261000.0   \n","7          7.0       53.0                143.0           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","1             0.0          1106.639839               usa  \n","2             NaN          1129.275654               usa  \n","3             1.0          1760.563380               usa  \n","5             NaN                  NaN               NaN  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  \n"]}],"source":["# print the dataframe\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["Now lets just throw away any additional rows with remaining NaN values "]},{"cell_type":"code","execution_count":314,"metadata":{},"outputs":[],"source":["# INSERT CODE TO THROW AWAY ANY ROW WITH \"NaN\" \n","# THIS TIME RE-DEFINE THE DATAFRAME WITHOUT THE \"NaN\"\n","# hint: read the documentation https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n","df = df.dropna()"]},{"cell_type":"code","execution_count":315,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  age_years  account_balance_usd  yearly_income_usd  \\\n","0          1.0       32.0               1232.0           140230.0   \n","1          1.0       32.0               1232.0           200615.0   \n","3          3.0       34.5              13023.0            56000.0   \n","6          6.0       53.0                143.0           261000.0   \n","7          7.0       53.0                143.0           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","1             0.0          1106.639839               usa  \n","3             1.0          1760.563380               usa  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  \n"]}],"source":["#PRINT THE DATA FRAME\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["## De-duplication\n","\n","Notice how the customer_id=1 is represented twice in the data set. \n","\n","This can be un-desireable, since it adds extra weight (importance) to that data point. \n","\n","For example, linear-regression would put twice as much importance on fitting that point as opposed to the others."]},{"cell_type":"code","execution_count":316,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\JaeHoBahng\\AppData\\Local\\Temp\\ipykernel_9560\\1085274366.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df.drop_duplicates(subset=['customer_id'], keep='first', inplace=True)\n"]}],"source":["# INSERT CODE TO REMOVE ROWS WITH DUPLICATES IN \"customer_id\" (KEEP THE FIRST VALUE ENCOUNTERS)\n","df.drop_duplicates(subset=['customer_id'], keep='first', inplace=True)"]},{"cell_type":"code","execution_count":317,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  age_years  account_balance_usd  yearly_income_usd  \\\n","0          1.0       32.0               1232.0           140230.0   \n","3          3.0       34.5              13023.0            56000.0   \n","6          6.0       53.0                143.0           261000.0   \n","7          7.0       53.0                143.0           261000.0   \n","\n","   is_house_owner  housing_payment_usd country_of_origin  \n","0             0.0          1106.639839               usa  \n","3             1.0          1760.563380               usa  \n","6             0.0          1224.346076               mex  \n","7             0.0          1214.285714               mex  \n"]}],"source":["# PRINT THE DATAFRAME\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["At this point we have relatively \"clean\" data"]},{"cell_type":"markdown","metadata":{},"source":["### Normalization \n","\n","Normalization of a vector is the process of making the vector have a unit length (i.e. $|\\mathbf{v}|=1$)\n","\n","$\\mathbf{v}_{norm}=\\frac{\\mathbf{v}}{|\\mathbf{v}|}$\n","\n","We can do a similar thing with a vector of data (e.g. h=heights with units ft). \n","\n","This is done using the following normalization process \n","\n","$\\mathbf{h}_{norm}=\\frac{\\mathbf{h}-\\mu_h}{\\sigma_h}$\n","\n","Where $\\mu_h, \\sigma_h$ are the mean (center) and standard deviation (width) of the height distribution.\n","\n","This process makes a new vector $\\mathbf{h}_{norm}$ which is a dimensionless quanity, meaning that it doesn't have units. \n","\n","The units cancel in the division arising during the normalization equation. \n","\n","This also forces the data into a standard range of roughly [-3 to 3] while still preserving the \"shape\" of the data.\n","\n","Often, when training machine learning models, it is important to normalize the data first. \n","\n","The model will have a much easier time \"fitting\" if every input is in a standard range of [-3 to 3]\n","\n","You can always \"un-do\" the normalization and re-assign the units by algebraically re-arranging the formula.\n","\n","$\\mathbf{h}=\\mathbf{h}_{norm} \\sigma_h+\\mu_h$\n","\n"]},{"cell_type":"code","execution_count":328,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\JaeHoBahng\\AppData\\Local\\Temp\\ipykernel_9560\\2351401685.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['housing_payment_usd'] = (df['housing_payment_usd']-df['housing_payment_usd'].mean())/df['housing_payment_usd'].std()\n"]}],"source":["# INSERT CODE TO NORMALIZE THE COLUMN \"housing_payment_usd\" \n","df['housing_payment_usd'] = (df['housing_payment_usd']-df['housing_payment_usd'].mean())/df['housing_payment_usd'].std()\n","\n"]},{"cell_type":"code","execution_count":332,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\JaeHoBahng\\AppData\\Local\\Temp\\ipykernel_9560\\366415157.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df.rename(columns = {\"housing_payment_usd\":\"housing_payment_normalized\"},inplace=True)\n"]}],"source":["# INSERT CODE TO RENAME THE COLUMN \"housing_payment_usd\" --> \"housing_payment_normalized\"\n","df.rename(columns = {\"housing_payment_usd\":\"housing_payment_normalized\"},inplace=True)"]},{"cell_type":"code","execution_count":333,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   customer_id  age_years  account_balance_usd  yearly_income_usd  \\\n","0          1.0       32.0               1232.0           140230.0   \n","3          3.0       34.5              13023.0            56000.0   \n","6          6.0       53.0                143.0           261000.0   \n","7          7.0       53.0                143.0           261000.0   \n","\n","   is_house_owner  housing_payment_normalized country_of_origin  \n","0             0.0                   -0.747008               usa  \n","3             1.0                    1.475213               usa  \n","6             0.0                   -0.347008               mex  \n","7             0.0                   -0.381196               mex  \n"]}],"source":["# PRINT THE DATA FRAME\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["Notice how the values for \"housing_payment_normalized\" are in the range -3 to 3, rather than 1000 to 2000$"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('ANLY590')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"2b6082c1c9eef3a910163f232074f2e179e34ed8469dd2c24c723d1290ad549e"}}},"nbformat":4,"nbformat_minor":1}
